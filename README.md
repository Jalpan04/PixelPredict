# PixelPredict ğŸ”¢âœï¸

[![Python Version](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![NumPy](https://img.shields.io/badge/numpy-1.20+-orange.svg)](https://numpy.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Live Demo](https://img.shields.io/badge/demo-online-brightgreen.svg)](https://number-id.onrender.com/)
[![MNIST](https://img.shields.io/badge/dataset-MNIST-lightgrey.svg)](http://yann.lecun.com/exdb/mnist/)

<div>
  <img src="https://img.shields.io/badge/Accuracy-97%25-success" alt="Model Accuracy" />
  <img src="https://img.shields.io/badge/Canvas-28x28-blueviolet" alt="Canvas Size" />
</div>

> PixelPredict is a web-based handwritten digit recognition application powered by a custom-built neural network, trained on the MNIST dataset. Draw digits and watch AI predict them in real-time!

## ğŸŒŸ Demo

Try the live demo at [https://number-id.onrender.com/](https://number-id.onrender.com/)

![PixelPredict Demo](demo.png)

## âœ¨ Features

- **ğŸ§  Custom Neural Network**: Handcrafted two-layer feedforward neural network with ~97% test accuracy
- **ğŸ–Œï¸ Interactive Canvas**: User-friendly 28Ã—28 drawing surface (scaled to 280Ã—280 pixels)
- **ğŸ“Š Real-time Visualization**: Dynamic confidence score visualization with bar charts
- **ğŸ“± Touch Support**: Works on both desktop and mobile devices
- **ğŸš€ Fast Response**: Real-time prediction through optimized Flask backend
- **ğŸ“ˆ Training Insights**: Includes visualization tools for model performance analysis

## ğŸ§  Neural Network Architecture

PixelPredict uses a custom neural network implemented from scratch with NumPy:

```
Input Layer (784 nodes) â†’ Hidden Layer (128 nodes, ReLU) â†’ Output Layer (10 nodes, Softmax)
```

### ğŸ” Technical Details

| Component          | Specification                                       |
|--------------------|----------------------------------------------------|
| **Input**          | 28Ã—28 grayscale images (flattened to 784 values)   |
| **Hidden Layer**   | 128 neurons with ReLU activation                   |
| **Output Layer**   | 10 neurons with Softmax activation                 |
| **Parameters**     | ~101K trainable parameters                         |
| **Loss Function**  | Cross-entropy                                      |
| **Optimization**   | Mini-batch gradient descent                        |
| **Weight Init**    | He initialization                                  |
| **Training**       | 20 epochs, batch size 64, learning rate 0.01       |
| **Performance**    | 97-98% training accuracy, 95-97% test accuracy     |

## ğŸ—‚ï¸ Project Structure

```
PixelPredict/
â”œâ”€â”€ ğŸ“„ app.py               # Flask app with neural network inference
â”œâ”€â”€ ğŸ“„ neural_training.py   # Neural network training script
â”œâ”€â”€ ğŸ“„ visualization.py     # Training visualization tools
â”œâ”€â”€ ğŸ“„ index.html           # Frontend interface
â”œâ”€â”€ ğŸ“„ requirements.txt     # Python dependencies
â”œâ”€â”€ ğŸ“ data/                # MNIST dataset files
â”‚   â”œâ”€â”€ train-images.idx3-ubyte
â”‚   â”œâ”€â”€ train-labels.idx1-ubyte
â”‚   â”œâ”€â”€ t10k-images.idx3-ubyte
â”‚   â””â”€â”€ t10k-labels.idx1-ubyte
â”œâ”€â”€ ğŸ“„ W1.npy               # Hidden layer weights
â”œâ”€â”€ ğŸ“„ b1.npy               # Hidden layer biases
â”œâ”€â”€ ğŸ“„ W2.npy               # Output layer weights
â”œâ”€â”€ ğŸ“„ b2.npy               # Output layer biases
â””â”€â”€ ğŸ“„ history.npy          # Training metrics history
```

## ğŸš€ Installation

### Prerequisites
- Python 3.7+
- pip (Python package manager)

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/pixelpredict.git
   cd pixelpredict
   ```

2. **Create and activate virtual environment**
   ```bash
   # Linux/macOS
   python -m venv venv
   source venv/bin/activate
   
   # Windows
   python -m venv venv
   venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   pip install matplotlib  # For visualization.py
   ```

4. **Download MNIST dataset**
   
   Download from [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/) and place in `data/` directory:
   ```
   data/
   â”œâ”€â”€ train-images.idx3-ubyte
   â”œâ”€â”€ train-labels.idx1-ubyte
   â”œâ”€â”€ t10k-images.idx3-ubyte
   â””â”€â”€ t10k-labels.idx1-ubyte
   ```

5. **Train the network (optional)**
   ```bash
   python neural_training.py
   ```

6. **Run the application**
   ```bash
   python app.py
   ```

7. **Access the application**
   
   Open your browser and navigate to [http://localhost:5000](http://localhost:5000)

## ğŸ–±ï¸ Usage

1. **Draw a digit** (0-9) on the canvas using your mouse or touch device
2. Click **Recognize** to see the prediction
3. View the **confidence scores** for each possible digit
4. Click **Clear** to reset and try again
5. **Visualize training metrics** (if you've run the training):
   ```bash
   python visualization.py
   ```

## ğŸ“Š Model Performance

![Training Metrics](https://img.shields.io/badge/PixelPredict-Training_Metrics-lightgrey?style=for-the-badge)

The neural network achieves:
- ğŸ“ˆ **Training accuracy**: 97-98%
- ğŸ¯ **Test accuracy**: 95-97%
- ğŸ“‰ **Loss convergence**: ~0.1-0.2 on test set

## ğŸŒ Deployment

PixelPredict is deployed on Render. To deploy your own instance:

1. **Push to GitHub** including all weight files
2. **Set up on Render**:
   - Create a new Web Service
   - Connect your GitHub repository
   - Set build command: `pip install -r requirements.txt`
   - Set start command: `gunicorn app:app`

## ğŸ› ï¸ Dependencies

| Library       | Purpose                              |
|---------------|--------------------------------------|
| **NumPy**     | Neural network computations          |
| **Flask**     | Web server                           |
| **Pillow**    | Image preprocessing                  |
| **Gunicorn**  | Production deployment                |
| **Matplotlib**| Training visualization (optional)    |

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can contribute:

1. **Fork** the repository
2. **Create** a feature branch:
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Commit** your changes:
   ```bash
   git commit -m 'Add an amazing feature'
   ```
4. **Push** to your branch:
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Submit** a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MNIST Dataset**: Yann LeCun and Corinna Cortes - [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
- **Deployment**: Render - [https://render.com/](https://render.com/)
- **Stack**: Flask, NumPy, JavaScript, and HTML5 Canvas

---
